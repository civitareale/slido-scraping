import re
import sys
import time
from bs4 import BeautifulSoup
import pandas as pd
from selenium import webdriver
import argparse

def scrape_slido(url, output_option=''):
    # Configuração do webdriver
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')  # para abrir o navegador em segundo plano

    driver = webdriver.Chrome(options=options)
    driver.get(url)
    time.sleep(10) # GAMBI!!! Melhorar isso
    page = driver.execute_script('return document.body.innerHTML')
    soup = BeautifulSoup(''.join(page), 'html.parser')

    questions = []
    votes = []
    authors = []

    # class_='card question-item' é o mais próximo que encontrei para mapear os cards que contém as perguntas
    for question in soup.find_all('div', class_='card question-item'):
        author_div = question.find('div', {'data-testid': 'question-author'})
        author_name = author_div.text if author_div else None

        vote_div = question.find('div', class_='score question-item__score score--only-upvotes')
        vote_count = vote_div.find('span').get_text() if vote_div else None

        question_div = question.find('div', {'data-testid': 'question-text'})
        question_text = question_div.find('span').get_text() if question_div else None

        questions.append(question_text)
        votes.append(vote_count)
        authors.append(author_name)

    # Cria o DataFrame
    data = {
        'QUEM': authors,
        'VOTOS': votes,
        'PERGUNTA': questions
    }

    df = pd.DataFrame(data)

    #Exibe o DataFrame
    # print(df.to_csv)
    # df.to_csv('output.csv')
    # df.to_json('output.json', orient='records')
    if output_option == 'table':
        df.to_string('output.txt')
    elif output_option == 'json':
        df.to_json('output.json', orient='records')
    elif output_option == 'csv':
        df.to_csv('output.csv', index=False)
    else:
        print(df)

# Processa argumento com a URL
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Adicionar uma URL do slido como parametro.")
        print("""
        Exemplo:python slido-scraping.py https://app.sli.do/event/abc123 [output_option]
        output_option: table, json, csv
              """)
    elif len(sys.argv) < 3:
        url = sys.argv[1]
        scrape_slido(url)
    else:
        url = sys.argv[1]
        output_option = sys.argv[2] #if len(sys.argv) >= 3 else 'csv'
        scrape_slido(url, output_option)
